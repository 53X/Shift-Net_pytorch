{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from models.soft_shift_net.innerSoftShiftTriple import InnerSoftShiftTriple\n",
    "#from models.accelerated_shift_net.accelerated_InnerShiftTriple import AcceleratedInnerShiftTriple\n",
    "from options.train_options import TrainOptions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DEFAULT OPTIONS TO INITIALIZE THE SHIFTMODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/mnt/hdd2/AIM/DAGM/Class4_def/' # ENTER HERE THE PATH YOU WANT TO USE AS DATAROOT\n",
    "options = '--dataroot {}'.format(dataroot).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser(options=None):\n",
    "    parser = TrainOptions()\n",
    "    parser.parse(options=options)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "           add_mask2input: 1                             \n",
      "                batchSize: 1                             \n",
      "                    beta1: 0.5                           \n",
      "               bottleneck: 512                           \n",
      "          checkpoints_dir: ./log                         \n",
      "                constrain: MSE                           \n",
      "           continue_train: False                         \n",
      "                 dataroot: /mnt/hdd2/AIM/DAGM/Class4_def/\t[default: ./datasets/Paris/train]\n",
      "             dataset_mode: aligned                       \n",
      "              discounting: 1                             \n",
      "              display_env: main                          \n",
      "             display_freq: 100                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 5                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "display_single_pane_ncols: 0                             \n",
      "          display_winsize: 256                           \n",
      "              epoch_count: 1                             \n",
      "                 fineSize: 256                           \n",
      "                     fuse: 0                             \n",
      "                 gan_type: vanilla                       \n",
      "               gan_weight: 0.2                           \n",
      "                gp_lambda: 10.0                          \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 100                           \n",
      "                 loadSize: 350                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: lambda                        \n",
      "            mask_sub_type: island                        \n",
      "               mask_thred: 1                             \n",
      "                mask_type: center                        \n",
      "              mask_weight: 400.0                         \n",
      "         max_dataset_size: inf                           \n",
      "                    model: shiftnet                      \n",
      "                 nThreads: 2                             \n",
      "               n_layers_D: 3                             \n",
      "                     name:                               \n",
      "                  ncritic: 5                             \n",
      "                      ndf: 64                            \n",
      "                      ngf: 64                            \n",
      "                    niter: 10000000                      \n",
      "              niter_decay: 0                             \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "             only_lastest: 0                             \n",
      "                output_nc: 3                             \n",
      "                  overlap: 4                             \n",
      "                    phase: train                         \n",
      "               print_freq: 50                            \n",
      "  residual_soft_attention: 0                             \n",
      "           resize_or_crop: resize_and_crop               \n",
      "          save_epoch_freq: 2                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                 shift_sz: 1                             \n",
      "                show_flow: 0                             \n",
      "                     skip: 0                             \n",
      "                 strength: 1                             \n",
      "                   stride: 1                             \n",
      "                   suffix:                               \n",
      "            triple_weight: 1                             \n",
      "         update_html_freq: 1000                          \n",
      "              use_dropout: False                         \n",
      "      use_spectral_norm_D: 1                             \n",
      "      use_spectral_norm_G: 0                             \n",
      "                  verbose: False                         \n",
      "              which_epoch: latest                        \n",
      "         which_model_netD: densenet                      \n",
      "         which_model_netG: unet_shift_triple             \n",
      "----------------- End -------------------\n"
     ]
    }
   ],
   "source": [
    "parser = get_parser(options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE INNER_SHIFT_TRIPLE LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models.InnerShiftTriple import InnerShiftTriple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parser.opt\n",
    "#opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_shift_triple = InnerSoftShiftTriple(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InnerSoftShiftTriple( ,triple_weight 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_shift_triple.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUE SPEED FORWARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE SIZE OF THE INPUT TENSOR IS (BATCH_SIZE, 256 * 2 (former | latter), 32, 32). LET CREATE A RANDOM TENSORS AND EVALUTE ITS FORWARD FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW WE NEED TO SET UP THE MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3832097828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c, h, w = (1, 256, 256)\n",
    "hh = h//2\n",
    "wh = w//2\n",
    "hm_size = 32\n",
    "mask = np.zeros((1, c, h, w))\n",
    "mask[..., hh - hm_size:hh + hm_size, wh - hm_size:wh + hm_size] = 1\n",
    "#mask[..., h - hh:, :] = 1\n",
    "mask_global=torch.ByteTensor(mask).cuda()#.cpu()\n",
    "plt.imshow(np.squeeze(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_shift_triple.set_mask(mask_global=mask_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = np.random.normal(0, 1, (1, 512, 32, 32))\n",
    "x_tr = torch.FloatTensor(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.1623e+01, 4.2083e+02, 1.3287e+05, 3.8174e+10, 1.0834e+00, 2.0902e+06,\n",
      "        1.6759e+12, 3.6475e+07, 8.6361e+11, 1.3226e+05, 2.0943e+02, 1.2834e+00,\n",
      "        6.9616e+01, 9.6458e+08, 7.9338e+16, 1.2977e+06, 4.0858e+08, 5.8713e+11,\n",
      "        4.0470e+00, 2.9696e+00, 6.9647e+02, 1.4685e+12, 1.9168e+04, 1.3760e+02,\n",
      "        8.6716e+00, 4.5522e+08, 2.1330e+05, 4.2584e+01, 2.2346e+03, 2.6328e+01,\n",
      "        1.0857e+02, 2.8503e+06, 4.0255e+04, 4.1393e+05, 8.9261e+03, 1.8489e+07,\n",
      "        2.7235e+02, 1.7932e+04, 2.1086e+07, 2.7400e+14, 1.3272e+06, 2.4196e+12,\n",
      "        8.0090e+09, 3.4557e+05, 2.2059e+00, 2.6400e+06, 7.9529e+00, 3.1501e+12,\n",
      "        3.9206e+07, 3.3290e+08, 1.8551e+11, 3.5402e+11, 2.2660e+01, 1.2339e+15,\n",
      "        3.5380e+03, 1.2675e+06, 2.6894e+07, 1.4581e+00, 3.0973e+01, 2.7343e+07,\n",
      "        1.2084e+03, 1.4702e+12, 3.6549e+05, 4.2439e+09, 5.0131e+06, 1.3502e+00,\n",
      "        2.7237e+11, 1.2924e+07, 2.4151e+08, 5.3048e+08, 2.9782e+06, 7.6644e+01,\n",
      "        3.3012e+01, 4.3753e+08, 1.5991e+02, 8.8885e+02, 9.9733e+06, 6.6299e+00,\n",
      "        3.4079e+01, 2.8192e+08, 1.3890e+11, 3.7205e+08, 4.4529e+01, 6.8740e+02,\n",
      "        5.0152e+24, 8.7180e+03, 6.7355e+02, 5.5665e+11, 5.9520e+04, 1.1982e+09,\n",
      "        8.5545e+12, 6.7881e+06, 1.5443e+06, 3.2362e+07, 4.9557e+03, 4.3821e+01,\n",
      "        1.9061e+10, 5.4743e+02, 1.8207e+09, 1.0002e+04, 3.7221e+06, 8.9135e+09,\n",
      "        2.5249e+08, 2.0433e+08, 1.2621e+07, 1.1890e+11, 1.4939e+05, 3.8831e+00,\n",
      "        4.0227e+03, 1.2279e+03, 1.2811e+04, 7.5364e+16, 2.2194e+08, 1.8553e+06,\n",
      "        4.1201e+01, 3.2804e+08, 2.5003e+03, 2.0565e+06, 9.0473e+01, 1.4412e+12,\n",
      "        1.8391e+08, 7.9298e+04, 1.0769e+03, 5.5427e+00, 4.4701e+03, 7.2344e+07,\n",
      "        1.0083e+00, 4.6330e+01, 1.6307e+10, 2.5334e+02, 9.9168e+07, 3.0595e+08,\n",
      "        1.0856e+07, 7.8391e+04, 1.3216e+03, 1.2958e+05, 8.8830e+07, 7.2211e+07,\n",
      "        3.3550e+06, 2.8090e+17, 1.2398e+00, 4.4249e+12, 3.2085e+02, 2.4486e+04,\n",
      "        2.8155e+10, 3.5826e+01, 1.6314e+09, 3.5495e+02, 1.3292e+04, 8.6661e+02,\n",
      "        1.1645e+02, 2.2493e+03, 3.5746e+00, 6.9198e+04, 1.5042e+06, 1.9794e+00,\n",
      "        1.7741e+04, 7.6903e+05, 8.6828e+04, 7.7509e+05, 1.8133e+04, 7.0248e+03,\n",
      "        1.6941e+05, 2.5231e+02, 3.1557e+03, 2.0044e+03, 1.3986e+10, 2.5865e+09,\n",
      "        3.8460e+01, 1.7297e+00, 2.1404e+04, 3.7395e+13, 3.2070e+09, 1.1938e+03,\n",
      "        7.4124e+02, 1.7425e+03, 6.5882e+06, 2.3940e+16, 7.4537e+00, 8.5996e+10,\n",
      "        1.4855e+08, 1.2083e+10, 1.8967e+04, 1.4731e+05, 4.5080e+06, 1.0638e+11,\n",
      "        9.8469e+09, 5.4549e+00, 4.2627e+01, 1.5706e+07, 1.5033e+04, 3.3344e+00,\n",
      "        1.5461e+03, 1.4922e+03, 6.1983e+11, 3.5997e+01, 7.8757e+00, 5.4882e+11,\n",
      "        7.9312e+02, 2.3489e+00, 5.1288e+08, 8.3321e+03, 1.4066e+00, 7.2748e+00,\n",
      "        5.6014e+06, 9.1684e+02, 2.1012e+05, 3.8463e+01, 1.0457e+02, 1.9117e+02,\n",
      "        2.6948e+06, 1.6767e+06, 5.1134e+09, 1.0259e+06, 1.0628e+00, 8.2076e+02,\n",
      "        4.5178e+03, 1.0359e+02, 9.4160e+01, 1.0003e+06, 1.8157e+02, 9.0894e+05,\n",
      "        1.2156e+06, 1.0807e+03, 7.9456e+06, 6.0395e+01, 5.2016e+01, 7.8849e+13,\n",
      "        1.4415e+05, 1.3326e+11, 8.2357e+03, 3.9088e+05, 2.7027e+00, 3.6041e+04,\n",
      "        2.2465e+06, 5.9897e+05, 1.7022e+01, 9.1640e+11, 6.1483e+02, 1.4763e+02,\n",
      "        2.9324e+05, 1.2849e+05, 5.1191e+03, 2.6852e+02, 1.3473e+07, 1.0185e+07,\n",
      "        1.0454e+01, 3.1849e+13, 3.8079e+13, 3.0829e+06, 1.2787e+05, 1.5943e+13,\n",
      "        3.1363e+02, 1.6047e+05, 5.0881e+03, 1.3045e+03, 2.8324e+02, 2.0885e+12,\n",
      "        2.6784e+16, 1.1890e+13, 3.8880e+04, 2.9810e+07, 4.0909e+10, 9.4842e+11,\n",
      "        5.0278e+09, 3.9849e+07, 2.0782e+00, 1.7702e+10, 1.7196e+07, 1.9502e+06,\n",
      "        3.5615e+02, 3.1791e+01, 4.1683e+02, 1.1583e+16, 8.2395e+07, 8.0642e+12,\n",
      "        1.6386e+13, 6.0058e+26, 6.1780e+02, 7.8254e+03, 2.7826e+00, 2.2315e+10,\n",
      "        4.5338e+01, 1.4779e+11, 1.4907e+03, 1.2836e+12, 8.0630e+07, 5.7796e+06,\n",
      "        5.5146e+00, 3.8509e+00, 4.5684e+04, 1.5844e+17, 2.2566e+03, 1.1620e+04,\n",
      "        6.8454e+01, 6.5647e+07, 1.3769e+00, 1.8674e+00, 1.9390e+04, 3.8893e+10,\n",
      "        2.4757e+03, 4.3586e+09, 7.5492e+03, 6.2564e+03, 1.2853e+02, 7.4732e+03,\n",
      "        2.6267e+07, 5.1135e+01, 8.8629e+16, 1.7661e+16, 4.1751e+07, 1.1134e+03,\n",
      "        5.9747e+00, 1.0443e+10, 9.5178e+00, 3.0593e+06, 7.0421e+10, 1.4076e+06,\n",
      "        1.9711e+13, 2.5280e+03, 2.4539e+06, 7.6000e+07, 6.9702e+07, 7.1506e+04,\n",
      "        1.1984e+01, 1.4750e+00, 2.7247e+03, 8.5814e+00, 7.1424e+10, 1.4494e+02,\n",
      "        3.2472e+05, 2.1271e+15, 7.0576e+02, 6.5668e+06, 1.3242e+00, 4.1893e+00,\n",
      "        1.4051e+09, 3.2246e+07, 2.7383e+10, 1.6929e+10, 6.2859e+10, 4.9782e+02,\n",
      "        1.8043e+08, 1.2821e+08, 2.5297e+00, 1.3341e+02, 4.0282e+01, 2.9928e+14,\n",
      "        3.4930e+02, 3.3017e+02, 2.4176e+04, 4.0641e+00, 2.0361e+01, 7.1108e+01,\n",
      "        1.8688e+02, 3.9872e+08, 3.9830e+04, 7.2384e+00, 1.8313e+05, 1.2066e+11,\n",
      "        1.5815e+03, 3.5964e+12, 1.5826e+01, 5.6648e+06, 2.2109e+07, 1.1277e+10,\n",
      "        3.4384e+20, 1.2879e+01, 1.9218e+05, 6.9605e+01, 8.4444e+03, 3.8038e+00,\n",
      "        4.1794e+10, 3.0554e+01, 4.1176e+01, 7.7952e+01, 2.5910e+04, 2.3875e+10,\n",
      "        3.8976e+02, 1.1803e+01, 2.4293e+03, 2.2234e+00, 2.9283e+02, 2.8870e+02,\n",
      "        1.5504e+01, 6.4423e+02, 2.8507e+01, 4.3862e+12, 5.1192e+02, 1.2413e+10,\n",
      "        1.1596e+04, 7.8601e+15, 3.3930e+16, 2.6943e+01, 1.8310e+07, 1.2570e+01,\n",
      "        3.7523e+02, 5.3679e+07, 1.0676e+06, 7.6969e+06, 1.0231e+08, 3.6056e+01,\n",
      "        4.3891e+02, 1.0412e+01, 2.3903e+12, 4.9986e+09, 4.0673e+05, 5.9963e+00,\n",
      "        9.8169e+00, 6.6573e+04, 1.4199e+03, 2.5497e+09, 2.3555e+05, 4.3590e+00,\n",
      "        4.9127e+00, 2.6007e+06, 1.4672e+08, 9.0455e+03, 3.2464e+02, 3.2381e+12,\n",
      "        1.9412e+05, 7.8048e+01, 8.1699e+00, 1.2639e+11, 7.0142e+03, 1.0733e+05,\n",
      "        5.7892e+04, 1.3240e+01, 1.6602e+01, 6.5864e+05, 8.5761e+03, 4.6153e+05,\n",
      "        6.7192e+13, 4.3352e+02, 1.6144e+03, 3.2402e+06, 2.8617e+05, 1.1592e+09,\n",
      "        7.4130e+02, 3.8694e+05, 4.3711e+02, 2.2806e+00, 2.7304e+00, 2.7952e+04,\n",
      "        1.5085e+08, 2.5749e+02, 2.0823e+01, 3.3684e+03, 2.4859e+00, 2.5149e+07,\n",
      "        2.2998e+05, 4.7934e+05, 4.7747e+09, 5.4531e+01, 2.2433e+06, 2.4673e+05,\n",
      "        9.0941e+09, 2.7276e+03, 3.1885e+06, 7.8414e+03, 1.1575e+12, 2.2518e+07,\n",
      "        6.4581e+00, 1.7402e+04, 1.1873e+12, 3.3613e+00, 7.4775e+01, 3.8492e+02,\n",
      "        2.7563e+01, 1.0559e+05, 9.1681e+05, 7.5782e+04, 1.0158e+00, 3.2081e+18,\n",
      "        1.1738e+11, 1.3521e+02, 2.5817e+17, 1.1158e+10, 2.2122e+03, 2.0934e+02,\n",
      "        5.0091e+02, 2.3300e+02, 5.9117e+07, 1.9258e+07, 3.9091e+12, 1.9244e+15,\n",
      "        5.0437e+05, 2.6150e+03, 4.7275e+01, 2.6633e+07, 9.6520e+00, 2.2130e+01,\n",
      "        4.7772e+04, 4.3606e+10, 2.8755e+01, 2.7478e+00, 1.0748e+08, 1.7320e+03,\n",
      "        2.0871e+09, 1.3681e+05, 1.5089e+01, 2.8113e+01, 1.8265e+14, 6.5378e+05,\n",
      "        2.6632e+03, 5.5036e+11, 4.7840e+03, 1.9594e+05, 2.5694e+08, 8.3109e+03,\n",
      "        7.8918e+03, 8.0002e+03, 2.3843e+09, 4.7373e+11, 4.3089e+06, 1.3586e+05,\n",
      "        8.9316e+03, 1.1472e+06, 1.0181e+03, 1.5970e+01, 1.1004e+03, 4.6461e+04,\n",
      "        2.5421e+03, 6.7746e+03, 5.2942e+05, 1.6075e+13, 2.6586e+02, 3.3361e+09,\n",
      "        1.3539e+02, 4.3012e+09, 5.4455e+03, 1.2366e+03, 4.2137e+00, 5.2448e+02,\n",
      "        1.9288e+01, 6.8657e+03, 4.0466e+06, 2.4715e+07, 2.4760e+12, 2.6505e+10,\n",
      "        8.7130e+05, 1.2765e+11, 1.1951e+00, 8.6287e+03, 7.6198e+08, 2.1914e+06,\n",
      "        2.4221e+02, 1.9513e+00, 2.3206e+11, 5.1055e+07, 1.4049e+08, 2.2041e+01,\n",
      "        9.9631e+03, 1.0237e+00, 3.4541e+05, 1.4476e+08, 7.0368e+12, 1.2829e+00,\n",
      "        1.8708e+09, 1.7852e+04, 7.8868e+03, 6.8714e+02, 1.6658e+05, 1.4942e+07,\n",
      "        6.0766e+00, 3.6655e+06, 7.7983e+13, 3.6211e+03, 9.3015e+05, 3.4400e+07,\n",
      "        1.4043e+02, 9.7478e+03, 5.2104e+11, 3.1606e+04, 5.3315e+18, 3.3183e+10,\n",
      "        3.0053e+04, 2.3014e+06, 1.5841e+04, 3.2059e+05, 1.4567e+18, 3.9017e+06,\n",
      "        4.3532e+03, 5.1949e+02, 2.3332e+05, 5.0934e+07, 2.0418e+12, 1.1301e+02,\n",
      "        1.1649e+02, 1.9290e+05, 4.5103e+04, 6.4535e+08, 3.9127e+05, 1.7477e+12,\n",
      "        1.1290e+03, 9.3368e+02, 1.0390e+05, 7.0961e+04, 1.0468e+09, 7.1462e+08,\n",
      "        8.4735e+07, 5.0358e+00, 2.9321e+06, 5.5596e+07, 6.8718e+04, 1.9342e+00,\n",
      "        5.8071e+04, 4.9543e+08, 2.4609e+01, 4.1970e+11, 1.3870e+13, 6.3987e+00,\n",
      "        1.1989e+09, 9.2771e+01, 8.4638e+01, 3.4895e+01, 1.2203e+05, 9.0848e+04,\n",
      "        7.7338e+05, 1.0091e+07, 1.5057e+01, 4.2892e+07, 9.3767e+07, 5.9634e+02,\n",
      "        2.7492e+04, 2.1914e+04, 1.0949e+00, 1.6458e+00, 3.5003e+07, 5.9659e+03,\n",
      "        1.6202e+02, 5.5067e+11, 6.3621e+06, 1.8626e+07, 1.1303e+04, 4.3992e+08,\n",
      "        1.6520e+01, 5.6493e+11, 1.7046e+17, 1.2491e+03, 4.4943e+00, 3.1757e+02,\n",
      "        1.0745e+06, 2.9560e+03, 5.3329e+07, 3.2819e+05, 3.1617e+02, 5.4966e+02,\n",
      "        1.5362e+04, 7.6875e+05, 4.9872e+01, 3.5534e+02, 4.1981e+16, 6.2034e+09,\n",
      "        2.2935e+07, 3.9552e+01, 9.7200e+08, 3.0879e+05, 2.2740e+09, 3.5949e+08,\n",
      "        2.0037e+01, 6.1288e+04, 3.7069e+14, 2.0138e+20, 1.7265e+02, 3.3141e+00,\n",
      "        6.0771e+08, 3.5161e+06, 2.8396e+12, 3.6308e+04, 1.3254e+17, 4.1949e+10,\n",
      "        7.3756e+08, 1.2846e+00, 2.7920e+02, 5.3620e+08, 1.6255e+12, 6.5924e+02,\n",
      "        2.6201e+01, 1.0275e+23, 5.0172e+01, 4.0883e+00, 2.1103e+12, 2.2625e+03,\n",
      "        4.3206e+09, 5.3420e+12, 2.4907e+02, 3.7384e+07, 2.3927e+03, 9.8895e+05,\n",
      "        2.3814e+02, 3.9032e+03, 4.7825e+10, 5.7978e+02, 1.0230e+00, 9.7594e+05,\n",
      "        8.8083e+07, 8.2839e+01, 4.3778e+05, 2.3355e+03, 9.9473e+05, 1.9006e+01,\n",
      "        1.7099e+06, 2.6967e+04, 3.3797e+06, 1.4216e+03, 1.1150e+00, 8.0985e+07,\n",
      "        1.1919e+13, 2.9620e+01, 5.8655e+07, 2.2260e+07, 2.7429e+05, 2.2334e+03,\n",
      "        9.8853e+01, 7.9751e+11, 1.6484e+01, 1.2396e+04, 6.0512e+00, 2.5642e+03,\n",
      "        1.6917e+00, 1.1111e+01, 9.0532e+10, 9.5225e+03, 1.0205e+16, 2.7334e+00,\n",
      "        8.6125e+12, 1.8793e+05, 1.7555e+00, 1.9320e+12, 4.1636e+14, 4.3919e+19,\n",
      "        4.5852e+02, 1.0526e+04, 3.4530e+12, 4.8471e+03, 4.8905e+00, 1.3880e+07,\n",
      "        1.0587e+04, 3.0356e+06, 3.8349e+04, 9.5792e+01, 2.9809e+01, 1.4721e+06,\n",
      "        3.7326e+11, 1.4176e+03, 1.5887e+01, 4.0548e+00, 2.1761e+02, 4.1943e+09,\n",
      "        5.0868e+09, 1.0036e+06, 6.9530e+21, 4.8474e+00, 1.3952e+16, 1.1975e+11,\n",
      "        4.5795e+04, 5.0828e+10, 9.7077e+05, 4.2258e+05, 1.9829e+05, 1.5016e+03,\n",
      "        5.7289e+02, 2.1206e+05, 2.8495e+02, 2.8001e+00, 5.8057e+03, 1.2765e+02,\n",
      "        2.3465e+00, 1.9024e+06, 2.8668e+02, 1.4477e+20, 1.2260e+09, 1.1194e+00,\n",
      "        1.3326e+11, 7.3298e+10, 2.0558e+13, 1.4064e+06, 6.3378e+02, 1.5847e+03,\n",
      "        1.0480e+00, 1.1005e+04, 4.2363e+11, 1.8950e+03, 5.4362e+17, 3.3132e+01,\n",
      "        2.8069e+00, 6.4847e+06, 2.2847e+05, 3.7401e+10, 1.6351e+11, 2.8625e+12,\n",
      "        3.9932e+00, 7.8772e+05, 2.5924e+03, 1.7773e+05, 2.6394e+07, 5.5870e+14,\n",
      "        4.1647e+00, 5.3323e+09, 7.0459e+10, 6.8927e+01, 2.0703e+14, 1.1370e+08,\n",
      "        9.6219e+15, 4.6748e+01, 1.0443e+08, 2.9702e+12, 2.9819e+01, 1.9539e+05,\n",
      "        8.3632e+02, 3.2083e+02, 3.4571e+05, 9.6224e+09, 7.0017e+10, 6.1243e+01,\n",
      "        1.5478e+00, 1.8333e+06, 1.9518e+18, 1.6421e+09, 1.4880e+11, 3.3751e+12,\n",
      "        3.2186e+08, 8.8223e+01, 1.8817e+03, 8.2608e+03, 4.4064e+04, 1.1349e+05,\n",
      "        1.4120e+11, 1.2852e+06, 1.1987e+00, 1.4296e+12, 1.3489e+09, 6.1168e+12,\n",
      "        8.8275e+03, 9.3962e+00, 5.6901e+05, 1.4913e+00, 1.5584e+01, 4.6950e+04,\n",
      "        9.3887e+08, 1.0963e+03, 9.2444e+06, 6.8553e+01, 8.8644e+10, 1.3138e+07,\n",
      "        2.4156e+01, 1.2330e+04, 8.7173e+00, 1.5326e+06, 5.7188e+02, 2.5411e+02,\n",
      "        8.8879e+01, 1.7789e+06, 1.3440e+06, 2.6851e+11, 1.9200e+03, 4.7617e+00,\n",
      "        1.7645e+19, 3.2963e+04, 4.6260e+05, 1.1679e+01, 3.5873e+03, 1.3680e+03,\n",
      "        9.4930e+11, 1.2190e+01, 1.5716e+04, 2.0306e+04, 4.5543e+04, 2.2666e+02,\n",
      "        2.1382e+02, 1.6597e+04, 4.0767e+05, 9.6786e+14, 8.1307e+09, 1.9681e+07,\n",
      "        1.0238e+11, 1.2018e+00, 1.2743e+05, 4.9300e+01, 2.0192e+08, 1.1349e+06,\n",
      "        1.7274e+07, 4.8607e+09, 3.8645e+05, 3.3250e+04, 2.9858e+03, 2.9999e+08,\n",
      "        3.7331e+08, 7.6043e+00, 4.3340e+05, 2.9716e+02, 1.6322e+09, 1.7119e+02,\n",
      "        1.8058e+06, 2.4657e+08, 8.4990e+02, 3.2923e+00, 2.8738e+08, 6.8728e+03,\n",
      "        2.3012e+02, 2.2941e+01, 5.1313e+09, 7.3031e+09, 8.2752e+09, 1.3331e+09,\n",
      "        4.0845e+01, 3.1509e+01, 1.9867e+09, 1.0980e+00, 1.1272e+00, 3.0370e+03,\n",
      "        5.3643e+02, 5.1505e+08, 6.3709e+02, 1.0969e+04, 9.2437e+02, 1.7148e+08,\n",
      "        9.7098e+03, 1.1628e+03, 4.4903e+11, 1.4744e+00, 1.2976e+08, 4.8000e+06,\n",
      "        1.3853e+03, 2.0584e+01, 6.8407e+00, 1.2975e+09, 1.0447e+09, 2.3130e+08,\n",
      "        2.6753e+05, 2.3019e+04, 4.3893e+00, 2.8972e+04, 6.3870e+01, 1.4142e+05,\n",
      "        2.2098e+07, 4.0161e+04, 9.0845e+05, 2.3721e+00, 1.5859e+08, 7.2598e+01,\n",
      "        1.1340e+07, 8.3970e+00, 5.9563e+02, 5.2155e+00, 3.9886e+08, 2.4329e+13,\n",
      "        6.0553e+01, 4.0744e+00, 3.4969e+01, 7.1263e+02, 1.3798e+05, 3.6607e+06,\n",
      "        1.2519e+11, 5.4853e+00, 1.2803e+02, 3.9646e+04, 2.1017e+09, 5.9380e+00],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "CPU times: user 16 ms, sys: 0 ns, total: 16 ms\n",
      "Wall time: 13.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time output = inner_shift_triple(x_tr.cuda())\n",
    "#output = inner_shift_triple(x_tr.cuda())\n",
    "#flag, indexes, ind_lst = inner_shift_triple(x_tr.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flag_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-648c6e3adaa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag_n\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'flag_n' is not defined"
     ]
    }
   ],
   "source": [
    "idx = tuple((np.where(flag_n == 1), f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrx[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(transition_matrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp[:, cp]\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = np.where(flag == 0)[0][indexes][0] == flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[:, 0, indexes] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(transition_matrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import util\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_mask(opt):\n",
    "    gMask_opts = {}\n",
    "    mask_global = torch.ByteTensor(1, 1, \\\n",
    "                                 opt.fineSize, opt.fineSize)\n",
    "\n",
    "        # Here we need to set an artificial mask_global(not to make it broken, so center hole is ok.)\n",
    "    mask_global.zero_()\n",
    "    mask_global[:, :, int(opt.fineSize/4) + opt.overlap : int(opt.fineSize/2) + int(opt.fineSize/4) - opt.overlap,\\\n",
    "                                int(opt.fineSize/4) + opt.overlap: int(opt.fineSize/2) + int(opt.fineSize/4) - opt.overlap] = 1  \n",
    "    \n",
    "    res = 0.06 # the lower it is, the more continuous the output will be. 0.01 is too small and 0.1 is too large\n",
    "    density = 0.25\n",
    "    MAX_SIZE = 300\n",
    "    maxPartition = 30\n",
    "    low_pattern = torch.rand(1, 1, int(res*MAX_SIZE), int(res*MAX_SIZE)).mul(255)\n",
    "    pattern = F.upsample(low_pattern, (MAX_SIZE, MAX_SIZE), mode='bilinear').data\n",
    "    low_pattern = None\n",
    "    pattern.div_(255)\n",
    "    pattern = torch.lt(pattern,density).byte()  # 25% 1s and 75% 0s\n",
    "    pattern = torch.squeeze(pattern).byte()\n",
    "    gMask_opts['pattern'] = pattern\n",
    "    gMask_opts['MAX_SIZE'] = MAX_SIZE\n",
    "    gMask_opts['fineSize'] = opt.fineSize\n",
    "    gMask_opts['maxPartition'] = maxPartition\n",
    "    gMask_opts['mask_global'] = mask_global\n",
    "    mask_global = util.create_gMask(gMask_opts) # create an initial random mask.   \n",
    "    return mask_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time mask_global = create_random_mask(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_global.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(mask_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_shift_triple.set_mask(mask_global=mask_global, threshold=opt.threshold, layer_to_last=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit output = inner_shift_triple.forward(x_tr.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE ENTIRE PROCESS IS PRETTY FAST, THE ISSUE WAS COMING FROM THE MASK GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENT AN ACCELERATE MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parser.opt\n",
    "opt.shift_sz = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.accelerated_InnerShiftTriple import AcceleratedInnerShiftTriple\n",
    "acce_inner_shift_triple = AcceleratedInnerShiftTriple(opt.threshold, opt.fixed_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acce_inner_shift_triple.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acce_inner_shift_triple.set_mask(mask_global=mask_global, threshold=opt.threshold, layer_to_last=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit output = acce_inner_shift_triple(x_tr.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acce_inner_shift_triple.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('THE SPEED UP IS {} FOLD'.format(582/115))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
